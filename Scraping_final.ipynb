{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRAPPING MAIIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contexte du code** \n",
    "\n",
    "Ce code a pour objectif de récupérer les URLs de chaque médecin généraliste référencé sur le site Maiia dans une région spécifiée. Une fois les URLs collectées, il parcourt chacune des pages correspondantes pour extraire des informations prédéfinies à partir du code source, puis les ajoute à un tableau de données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATION D'UN PREMIER DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je creer un dataframe qui regroupe \n",
    "- l'URL\n",
    "- ADRESSE \n",
    "- CONVENTION\n",
    "\n",
    "a partir de l'url et d'un petit traitement de donnée je peux récup \n",
    "- ID\n",
    "- Medical specialty\n",
    "- consultation availability etc..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Liste de User-Agent pour changer à chaque requête\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.59\"\n",
    "]\n",
    "\n",
    "\n",
    "### modifier le chemin d'accées en fonction de la regions souhaité\n",
    "url = \"https://www.maiia.com/medecin-generaliste/11-ILE-DE-FRANCE?page=\"\n",
    "medecin_urls = []\n",
    "\n",
    "for i in range(1, 5):\n",
    "    try:\n",
    "        # Choisir un User-Agent aléatoire\n",
    "        headers = {\n",
    "            \"User-Agent\": random.choice(user_agents)\n",
    "        }\n",
    "\n",
    "        # Faire la requête de la page HTLM\n",
    "        page = requests.get(url + str(i), headers=headers)\n",
    "        page.raise_for_status()  # Vérifier si la requête a échoué\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "        # Sélectionner tous les liens des médecins\n",
    "        medecin_lien = soup.select(\"a.mui-1wisq94\")\n",
    "\n",
    "        # Extraire les URLs valides\n",
    "        urls_page = [\"https://www.maiia.com\" + lien[\"href\"] for lien in medecin_lien if lien.has_attr(\"href\")]\n",
    "        \n",
    "        # Ajouter les URLs extraites à la liste\n",
    "        medecin_urls.extend(urls_page)\n",
    "\n",
    "        # Attendre un délai aléatoire entre chaque requête pour ne pas surcharger les serveur du site \n",
    "        time.sleep(random.uniform(2, 15))\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur avec la page {i}: {e}\")\n",
    "\n",
    "# Afficher les résultats\n",
    "#print(medecin_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Liste de User-Agent pour changer à chaque requête\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.59\"\n",
    "]\n",
    "\n",
    "# URL de base pour\n",
    "url = \"https://www.maiia.com/medecin-generaliste/11-ILE-DE-FRANCE?page=\"\n",
    "\n",
    "\n",
    "medecin_urls = []\n",
    "adresses = []\n",
    "conventions = []\n",
    "\n",
    "\n",
    "for i in range(1, 2):\n",
    "    try:\n",
    "        # Choisir un User-Agent aléatoire\n",
    "        headers = {\n",
    "            \"User-Agent\": random.choice(user_agents)\n",
    "        }\n",
    "\n",
    "        # Faire la requête HTTP et récupérer le contenu de la page\n",
    "        page = requests.get(url + str(i), headers=headers)\n",
    "        page.raise_for_status()  \n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "        # Sélection des liens des médecins\n",
    "        medecin_lien = soup.select(\"a.mui-1wisq94\")\n",
    "\n",
    "        # Sélection des informations supplémentaires\n",
    "        adresses_med = soup.select(\".prat__address\")\n",
    "        convention_med = soup.select(\".prat__secu\")\n",
    "\n",
    "        # Extraire les URLs des médecins\n",
    "        urls_page = [\"https://www.maiia.com\" + lien[\"href\"] for lien in medecin_lien if lien.has_attr(\"href\")]\n",
    "        medecin_urls.extend(urls_page)\n",
    "\n",
    "        # Extraire les adresses\n",
    "        adresses_page = [adresse.get_text(strip=True) for adresse in adresses_med]\n",
    "        adresses.extend(adresses_page)\n",
    "\n",
    "        # Extraire les informations de convention\n",
    "        conventions_page = [convention.get_text(strip=True) for convention in convention_med]\n",
    "        conventions.extend(conventions_page)\n",
    "\n",
    "        # delais\n",
    "        time.sleep(random.uniform(2, 16))\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur avec la page {i}: {e}\")\n",
    "        continue  # Passer à la page suivante si une erreur se produit\n",
    "\n",
    "# Créer un DataFrame \n",
    "data = {\n",
    "    \"URL\": medecin_urls,\n",
    "    \"Adresse\": adresses,\n",
    "    \"Convention\": conventions\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"base_BS_ILE_DE_FRANCE.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELENIUM SCRAPING DES PAGES MEDECINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur avec la page 31: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=31 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14103c5d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 32: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=32 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14103c250>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 33: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=33 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1414b6d50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 34: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=34 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1414b6d50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 35: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=35 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14103e610>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 36: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=36 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1414b5ed0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 37: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=37 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1414dc850>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 38: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=38 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1414b5f50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 39: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=39 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1414dcd50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 40: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=40 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1414b79d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 41: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=41 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1414dd0d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 42: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=42 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1414b68d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 43: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=43 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1426c3090>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 44: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=44 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1414b7090>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 45: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=45 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1412e8350>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 46: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=46 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1412ea310>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 47: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=47 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1412e9a10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 48: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=48 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1412ea110>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 49: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=49 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1412e9a50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 50: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=50 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1425b2b10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 51: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=51 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1412e9c50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 52: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=52 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14250b5d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 53: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=53 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141094950>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 54: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=54 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141740d10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 55: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=55 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141096490>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 56: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=56 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141096690>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 57: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=57 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141096690>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 58: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=58 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1410967d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 59: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=59 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141097410>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 60: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=60 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141096210>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 61: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=61 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1410960d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 62: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=62 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141096450>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 63: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=63 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141096810>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 64: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=64 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141097a90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 65: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=65 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141097710>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 66: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=66 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1410949d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 67: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=67 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141097290>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 68: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=68 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141096e50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Erreur avec la page 69: HTTPSConnectionPool(host='www.maiia.com', port=443): Max retries exceeded with url: /medecin-generaliste/11-ILE-DE-FRANCE?page=69 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x141097ed0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Liste de User-Agent pour changer à chaque requête\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.59\"\n",
    "]\n",
    "\n",
    "# URL de base pour\n",
    "url = \"https://www.maiia.com/medecin-generaliste/11-ILE-DE-FRANCE?page=\"\n",
    "\n",
    "\n",
    "medecin_urls = []\n",
    "adresses = []\n",
    "conventions = []\n",
    "\n",
    "\n",
    "for i in range(1, 70):\n",
    "    try:\n",
    "        # Choisir un User-Agent aléatoire\n",
    "        headers = {\n",
    "            \"User-Agent\": random.choice(user_agents)\n",
    "        }\n",
    "\n",
    "        # Faire la requête HTTP et récupérer le contenu de la page\n",
    "        page = requests.get(url + str(i), headers=headers)\n",
    "        page.raise_for_status()  \n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "        # Sélection des liens des médecins\n",
    "        medecin_lien = soup.select(\"a.mui-1wisq94\")\n",
    "\n",
    "        # Sélection des informations supplémentaires\n",
    "        adresses_med = soup.select(\".prat__address\")\n",
    "        convention_med = soup.select(\".prat__secu\")\n",
    "\n",
    "        # Extraire les URLs des médecins\n",
    "        urls_page = [\"https://www.maiia.com\" + lien[\"href\"] for lien in medecin_lien if lien.has_attr(\"href\")]\n",
    "        medecin_urls.extend(urls_page)\n",
    "\n",
    "        # Extraire les adresses\n",
    "        adresses_page = [adresse.get_text(strip=True) for adresse in adresses_med]\n",
    "        adresses.extend(adresses_page)\n",
    "\n",
    "        # Extraire les informations de convention\n",
    "        conventions_page = [convention.get_text(strip=True) for convention in convention_med]\n",
    "        conventions.extend(conventions_page)\n",
    "\n",
    "        # delais\n",
    "        time.sleep(random.uniform(2, 16))\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur avec la page {i}: {e}\")\n",
    "        continue  # Passer à la page suivante si une erreur se produit\n",
    "\n",
    "# Créer un DataFrame \n",
    "data = {\n",
    "    \"URL\": medecin_urls,\n",
    "    \"Adresse\": adresses,\n",
    "    \"Conventionbs\": conventions\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"BASE_SECOURS/BS_ILE_DE_FRANCE.csv\",sep=';', index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import re\n",
    "import time\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Configuration du navigateur\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "logging.basicConfig(filename='scraping_errors.log', level=logging.DEBUG)\n",
    "\n",
    "def init_driver():\n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "def scrape_url(url):\n",
    "    driver = init_driver()\n",
    "    result = {\n",
    "        'URL': url,\n",
    "        'Disponibilité': None,\n",
    "        'Méthodes de paiement': None,\n",
    "        'Tarifs': None,\n",
    "        'Date de diplôme': None,\n",
    "        'Horaires': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "\n",
    "        # Accéder à la page du médecin\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Attendre que la page soit chargée\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            lambda d: d.execute_script('return document.readyState') == 'complete'\n",
    "        )\n",
    "\n",
    "        # Récupérer la disponibilité\n",
    "\n",
    "        # Récupérer la disponibilité en ligne\n",
    "        try:\n",
    "            # Chercher l'élément avec la classe 'info' qui indique qu'il n'y a plus de disponibilité\n",
    "            info_elements = driver.find_elements(By.CSS_SELECTOR, \"p.info\")\n",
    "            if info_elements:\n",
    "                result['Disponibilité en ligne'] = info_elements[0].text.strip()\n",
    "            else:\n",
    "                # Si cet élément n'est pas trouvé, continuer normalement avec les autres étapes\n",
    "                disponibilite_elements = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.calendar-info-availability span.info-availability span.date.percy-hidden\"))\n",
    "                )\n",
    "                if disponibilite_elements:\n",
    "                    result['Disponibilité'] = disponibilite_elements[0].text.strip()\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Disponibilité non trouvée pour {url}: {e}\")\n",
    "\n",
    "        # Tarifs\n",
    "        try:\n",
    "            tarif_med = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"tr.MuiTableRow-root th.MuiTableCell-root + td.MuiTableCell-root\"))\n",
    "            )\n",
    "            if tarif_med:\n",
    "                tarifs = [element.text for element in tarif_med]\n",
    "                result['Tarifs'] = ', '.join(tarifs)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Tarifs non trouvés pour {url}: {e}\")\n",
    "\n",
    "        # Méthodes de paiement - Solution améliorée\n",
    "        try:\n",
    "            # Attendre que la section soit présente (pas nécessairement visible)\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//h3[contains(., 'Méthodes de paiement')]\")))\n",
    "            \n",
    "            # Faire défiler la page vers l'élément pour le rendre visible\n",
    "            payment_title = driver.find_element(By.XPATH, \"//h3[contains(., 'Méthodes de paiement')]\")\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", payment_title)\n",
    "            time.sleep(1)  # Petit délai pour le défilement\n",
    "            \n",
    "            # Trouver la section des méthodes de paiement\n",
    "            payment_section = driver.find_element(By.XPATH, \"//h3[contains(., 'Méthodes de paiement')]/following-sibling::div\")\n",
    "            \n",
    "            # Récupérer toutes les méthodes actives (sans la classe tag--ko)\n",
    "            methods = []\n",
    "            tags = payment_section.find_elements(By.CLASS_NAME, \"tag\")\n",
    "            for tag in tags:\n",
    "                if 'tag--ko' not in tag.get_attribute('class'):\n",
    "                    methods.append(tag.text.strip())\n",
    "            \n",
    "            if methods:\n",
    "                result['Méthodes de paiement'] = ', '.join(methods)\n",
    "            else:\n",
    "                logging.warning(f\"Aucune méthode de paiement active trouvée pour {url}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erreur méthodes de paiement pour {url}: {e}\")\n",
    "            # Essayez de récupérer le HTML pour déboguer\n",
    "            try:\n",
    "                with open(f\"error_page_{result['ID']}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(driver.page_source)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Convention - Solution similaire à Méthodes de paiement\n",
    "        try:\n",
    "            # Attendre que la section des conventions soit présente\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 'MuiBox-root') and contains(., 'Conventionné')]\")))\n",
    "            \n",
    "            # Trouver la section des conventions\n",
    "            convention_section = driver.find_element(By.XPATH, \"//div[contains(@class, 'MuiBox-root') and contains(., 'Conventionné')]\")\n",
    "            \n",
    "            # Récupérer toutes les conventions actives (sans la classe tag--ko)\n",
    "            conventions = []\n",
    "            convention_tags = convention_section.find_elements(By.CLASS_NAME, \"tag\")\n",
    "            for tag in convention_tags:\n",
    "                if 'tag--ko' not in tag.get_attribute('class'):\n",
    "                    conventions.append(tag.text.strip())\n",
    "            \n",
    "            if conventions:\n",
    "                result['Convention'] = ', '.join(conventions)\n",
    "            else:\n",
    "                logging.warning(f\"Aucune convention active trouvée pour {url}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erreur conventions pour {url}: {e}\")\n",
    "            try:\n",
    "                with open(f\"error_page_{result['ID']}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(driver.page_source)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Date de diplôme\n",
    "        try:\n",
    "            date_diplome_elements = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div[data-testid='diplomas-section'] span.cv-date\"))\n",
    "            )\n",
    "            if date_diplome_elements:\n",
    "                result['Date de diplôme'] = date_diplome_elements[0].text.strip()\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Date de diplôme non trouvée pour {url}: {e}\")\n",
    "\n",
    "        # Horaires\n",
    "        try:\n",
    "            horaires_elements = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"ul li.mui-182gbo5\"))\n",
    "            )\n",
    "            horaires_med = {}\n",
    "            for element in horaires_elements:\n",
    "                jour = element.find_element(By.CSS_SELECTOR, \"span.mui-1wwj1lu\").text.strip()\n",
    "                horaires_plage = element.find_element(By.CSS_SELECTOR, \"span.mui-9rvw1i\").text.strip()\n",
    "                horaires_med[jour] = horaires_plage\n",
    "            \n",
    "            horaires_str = \", \".join([f\"{jour}: {plage}\" for jour, plage in horaires_med.items()])\n",
    "            result['Horaires'] = horaires_str\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Horaires non trouvés pour {url}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erreur générale pour {url}: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        return result\n",
    "\n",
    "def scrape_all_urls(medecin_urls):\n",
    "    data = []\n",
    "    \n",
    "    # Réduire le nombre de workers pour éviter les problèmes de concurrence\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [executor.submit(scrape_url, url) for url in medecin_urls]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            data.append(future.result())\n",
    "            time.sleep(1)  # Petit délai entre chaque requête\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    all_data = scrape_all_urls(medecin_urls)\n",
    "    df_indiv = pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "\n",
    "df_indiv.to_csv(\"BASE_SECOURS/SELLENIUM_ile_de_france.csv\",sep=';', index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(df_indiv, df, on='URL', how='outer')\n",
    "df_indiv.to_csv(\"DATA/ile_de_france.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
